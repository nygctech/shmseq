{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make one big normalized expression anndata from small h5ad files\n",
    "\n",
    "Input files:<br>\n",
    ".h5ad files per sample: created in b. preprocessing_normcounts2anndatas<br>\n",
    "Final metadata file: created in c. collect_raw_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import scanpy as sc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing anndatas.. 1 out of 34\n",
      "processing anndatas.. 2 out of 34\n",
      "processing anndatas.. 3 out of 34\n",
      "processing anndatas.. 4 out of 34\n",
      "processing anndatas.. 5 out of 34\n",
      "processing anndatas.. 6 out of 34\n",
      "processing anndatas.. 7 out of 34\n",
      "processing anndatas.. 8 out of 34\n",
      "processing anndatas.. 9 out of 34\n",
      "processing anndatas.. 10 out of 34\n",
      "processing anndatas.. 11 out of 34\n",
      "processing anndatas.. 12 out of 34\n",
      "processing anndatas.. 13 out of 34\n",
      "processing anndatas.. 14 out of 34\n",
      "processing anndatas.. 15 out of 34\n",
      "processing anndatas.. 16 out of 34\n",
      "processing anndatas.. 17 out of 34\n",
      "processing anndatas.. 18 out of 34\n",
      "processing anndatas.. 19 out of 34\n",
      "processing anndatas.. 20 out of 34\n",
      "processing anndatas.. 21 out of 34\n",
      "processing anndatas.. 22 out of 34\n",
      "processing anndatas.. 23 out of 34\n",
      "processing anndatas.. 24 out of 34\n",
      "processing anndatas.. 25 out of 34\n",
      "processing anndatas.. 26 out of 34\n",
      "processing anndatas.. 27 out of 34\n",
      "processing anndatas.. 28 out of 34\n",
      "processing anndatas.. 29 out of 34\n",
      "processing anndatas.. 30 out of 34\n",
      "processing anndatas.. 31 out of 34\n",
      "processing anndatas.. 32 out of 34\n",
      "processing anndatas.. 33 out of 34\n",
      "processing anndatas.. 34 out of 34\n"
     ]
    }
   ],
   "source": [
    "h5ad_path_reprocessed_norm = '/norm_data' # folder with all small norm_counts h5ad\n",
    "files_done = [i.split(\".h5ad\")[0] for i in os.listdir(h5ad_path_reprocessed_norm)]\n",
    "\n",
    "counter = 1\n",
    "for f in files_done:\n",
    "    \n",
    "    if f == '.DS_Store':\n",
    "        continue \n",
    "    \n",
    "    filename = f + \".h5ad\"\n",
    "    p = sc.read_h5ad(os.path.join(h5ad_path_reprocessed_norm, filename))\n",
    "    adata_n = p.copy()\n",
    "    #adata_n.obs_names_make_unique()\n",
    "    \n",
    "    if counter == 1:\n",
    "        adata_large = adata_n\n",
    "        #adata_large.obs['batch_key'] = f\n",
    "    else:\n",
    "        adata_large = adata_large.concatenate(adata_n)\n",
    "    \n",
    "    print('processing anndatas..', counter, 'out of', len(files_done))\n",
    "    counter += 1\n",
    "    \n",
    "adata_large.obs.index = [str(i.split(\"-\")[0]) for i in adata_large.obs.index]\n",
    "adata_large.obs.drop(['batch'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge with UMI and Gene counts metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Name Mouse Type  sections  UMIs  Genes  patch  \\\n",
      "spotch_patches                                                              \n",
      "10015CN38_C1_10_10  10015CN38_C1   M1C   GF         3  3068   2067  10_10   \n",
      "10015CN38_C1_10_11  10015CN38_C1   M1C   GF         3  3334   2302  10_11   \n",
      "10015CN38_C1_10_12  10015CN38_C1   M1C   GF         3  2915   1987  10_12   \n",
      "10015CN38_C1_10_13  10015CN38_C1   M1C   GF         3  4282   2598  10_13   \n",
      "10015CN38_C1_10_14  10015CN38_C1   M1C   GF         3  6652   3632  10_14   \n",
      "\n",
      "                    spots   x   y                     annotation  \\\n",
      "spotch_patches                                                     \n",
      "10015CN38_C1_10_10    444  10  10                         pellet   \n",
      "10015CN38_C1_10_11    444  10  11                         pellet   \n",
      "10015CN38_C1_10_12    444  10  12                         pellet   \n",
      "10015CN38_C1_10_13    444  10  13              mucosa and pellet   \n",
      "10015CN38_C1_10_14    444  10  14  epithelium and lamina propria   \n",
      "\n",
      "                          annotation2 short_annotations  \n",
      "spotch_patches                                           \n",
      "10015CN38_C1_10_10             pellet                PE  \n",
      "10015CN38_C1_10_11             pellet                PE  \n",
      "10015CN38_C1_10_12             pellet                PE  \n",
      "10015CN38_C1_10_13  mucosa and pellet              MUPE  \n",
      "10015CN38_C1_10_14         epithelium                 E  \n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"/Metadata_final.csv\", sep = \"\\t\", index_col = 0)\n",
    "print(metadata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop(['patch', 'x', 'y', 'Mouse', 'Type', 'annotation', 'Name', 'annotation2'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_large.obs = pd.merge(adata_large.obs, metadata, left_index=True, right_index=True, how = \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write large anndata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'sample' as categorical\n",
      "... storing 'patch' as categorical\n",
      "... storing 'annotation' as categorical\n",
      "... storing 'Specimen_ID' as categorical\n",
      "... storing 'Region' as categorical\n",
      "... storing 'short_annotations' as categorical\n"
     ]
    }
   ],
   "source": [
    "### This is the file that exists on google drive\n",
    "adata_large.write_h5ad(filename = '/anndata.h5ad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_large.obs.to_csv(\"/Metadata_final_with_mouse_info.csv\", sep = \"\\t\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
